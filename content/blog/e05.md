+++
Description = "To Err is Human. Self reflection about how the individual user is a wildcard for a project. Scaffolding the experience with good documentation is helpful, but PEBCAK will always be a thing. "
Date = 2021-04-21T10:25:26-05:00
PublishDate = 2021-04-21T10:25:26-05:00 # this is the datetime for the when the epsiode was published. This will default to Date if it is not set. Example is "2016-04-25T04:09:45-05:00"
title = "PEBCAK and Covid"
#blog_banner = ""
blog_image = "img/episode/e05/e05.png"
images = ["img/episode/e05/e05.png"]
#Author = ""
#aliases = ["/##"]
draft = true
+++
### Where are my Episodes?
My release schedule was recently disrupted due to illness. Luckily I have been healthy but members of my family and academic institutions they attend were impacted by the Covid pandemic. Thankfully, no one in my family contracted Covid, but we had to practice quarantine procedures to keep ourselves and our community safe. This took time away from the project and something like this may occur in the future.

### What's the Status with Documentation?
I recently have been banging my head against the wall trying to get [wallabag](https://wallabag.org) to run in docker on my raspberry pi 4. This task seems like a pretty big pain point in the community because their docker containers are currently not multiarch so they have no official offering for the arm platform.

Searching around the internet, there are a lot of threads about people struggling with this issue and a variety of solutions. Some of these suggest using community [docker]()images or even [building your own arm container using docker](). I personally went the route of docker hub and am using [this image](https://hub.docker.com/r/ikaruswill/wallabag) with the 2.4.2 tag in the compose file.

I had a lot of issues getting the image to work. My frustration and eventual success is chronicled on [/r/selfhosted]() for the curious viewer. A user did provide a working compose file for me and was really awesome in terms of helping me troubleshoot. It's always nice when someone takes that time and care in on an asynchronous platform like reddit. This brings me to the reflection of what **I WAS DOING WRONG**.

### The Problem Exists Between Chair and Keyboard
Wallabag does have [docker documentation](https://doc.wallabag.org/en/developer/docker.html) but I didn't like the approach of having to clone their repo and use their compose file. Since I am using LSIO SWAG as a reverse proxy, I like to try to follow their approach. LSIO does provide a [wallbag proxy config](https://github.com/linuxserver/reverse-proxy-confs/blob/master/wallabag.subdomain.conf.sample) so that was a great place to start. I personally like to use my own naming conventions with my containers (like using "keep.mydomain.com" rather than their suggested "wallabag.mydomain.com") which I found complicates things a bit.
Once I had Wallabag working on the local host, I wanted to be able to access it using my domain. There are a few things that kept me from doing this effectively. 
1. The base url is VERY picky. When putting in your local host IP in the compose config of 

> \- SYMFONY__ENV__DOMAIN_NAME=http://XXX.XXX.XXX.XXX:YY

It is really important that you put in the port number for your container. Typically, the volume section will have something like this:

>ports:     
>&nbsp; &nbsp; &nbsp;\- "80:80"
 
 So it may look like this with a local ip of your docker host:
 > \- SYMFONY__ENV__DOMAIN_NAME=10.10.0.4:80

and if you are using a different external port in your compose, it may look like this:

 > \- SYMFONY__ENV__DOMAIN_NAME=10.10.0.4:8000

So I spend a lot of time bringing the containers down and up and messing with this parameter. I tried `https://` and `http://` with my domain name. I also tried the domain with `:8000` at the end as well. and I always got a `502` error from my SWAG instance. So what did I do next other than wasting hours searching online? I messed with the proxy of course!
2. LEARN THE NAMING SCHEMES! I have learned them now but if I had been a careful reader, it would have saved me LOTS of time. Here is the `_template` config from LSIO:
>## Version 2020/12/09
# REMOVE THIS LINE BEFORE SUBMITTING: The structure of the file (all of the existing lines) should be kept as close as possible to this template.
# REMOVE THIS LINE BEFORE SUBMITTING: Look through this file for <tags> and replace them. Review other sample files to see how things are done.
# REMOVE THIS LINE BEFORE SUBMITTING: The comment lines at the top of the file (below this line) should explain any prerequisites for using the proxy such as DNS or app settings.
# make sure that your dns has a cname set for <container_name> and that your <container_name> container is not using a base url

server {
    listen 443 ssl;
    listen [::]:443 ssl;

    server_name <container_name>.*;

    include /config/nginx/ssl.conf;

    client_max_body_size 0;

    # enable for ldap auth, fill in ldap details in ldap.conf
    #include /config/nginx/ldap.conf;

    # enable for Authelia
    #include /config/nginx/authelia-server.conf;

    location / {
        # enable the next two lines for http auth
        #auth_basic "Restricted";
        #auth_basic_user_file /config/nginx/.htpasswd;

        # enable the next two lines for ldap auth
        #auth_request /auth;
        #error_page 401 =200 /ldaplogin;

        # enable for Authelia
        #include /config/nginx/authelia-location.conf;

        include /config/nginx/proxy.conf;
        resolver 127.0.0.11 valid=30s;
        set $upstream_app <container_name>;
        set $upstream_port <port_number>;
        set $upstream_proto <http or https>;
        proxy_pass $upstream_proto://$upstream_app:$upstream_port;

        # REMOVE THIS LINE BEFORE SUBMITTING: Additional proxy settings such as headers go below this line, leave the blank line above.
    }

    # REMOVE THIS LINE BEFORE SUBMITTING: Some proxies require one or more additional location blocks for things like API or RPC endpoints.
    # REMOVE THIS LINE BEFORE SUBMITTING: If the proxy you are making a sample for does not require an additional location block please remove the commented out section below.
    # location ~ (/<container_name>)?/api {
    #     include /config/nginx/proxy.conf;
    #     resolver 127.0.0.11 valid=30s;
    #     set $upstream_app <container_name>;
    #     set $upstream_port <port_number>;
    #     set $upstream_proto <http or https>;
    #     proxy_pass $upstream_proto://$upstream_app:$upstream_port;
    #
    #     # REMOVE THIS LINE BEFORE SUBMITTING: Additional proxy settings such as headers go below this line, leave the blank line above.
    # }
    }
 >
 **CONTAINER NAME** is super important!! In my compose file, I had it setup like this:
``` 
wallabag:
   image: ikaruswill/wallabag:2.4.2
   environment:
```
and other containers looked like this:
```
  audacity:
    image: ghcr.io/linuxserver/audacity
    container_name: audacity
    environment:
```
See the difference? I didn't at first and I paid for it in blood, sweat and tears. This is probably due to my ignorance of the semantics of docker-compose. In my custom compose file, I had renamed the `container_name:` keep but left the top declaration as `wallabag` and my proxy config renamed as `keep.subdomain.conf`. My best guess is that **EVERYTHING** needs to have the same name. Adjusting my compose to look like this: 
```
keep:
   image: ikaruswill/wallabag:2.4.2
   container_name: keep
   environment:
```
and the symfony variable as this:
 > \- SYMFONY__ENV__DOMAIN_NAME=https://keep.mydomain.com

resulted in a final success.

### Documentation Could be Improved, But Not By Me
I think Wallabag could up their game on their documentation but the project and I are not currently in alignment to do so. Perhaps I could upstream my efforts to another project. LSIO does not currently offer Wallabag as an option so I don't really know where this effort could best be put to use.

### Bonus
I have used Feedly as an RSS catcher for 10+ years. They have a nice feature called boards that you can save articles to and read later. BUT, you cannot export any of your saved articles from feedly which is a huge bummer. Wallabag does import data from several different services but feedly isn't one of them. I had an idea that if I could get my links from feedly in a `.csv` file, I could maybe get them into Wallabag since the Instapaper import uses `csv`. While searching the internet I found [this](https://towardsdatascience.com/quickly-extract-all-links-from-a-web-page-using-javascript-and-the-browser-console-49bb6f48127b) article that can scrape all the URLs from a website and place them in a neat table for you. I logged into my feedly account from the website and used this script in my board section to get all my URLs!! Then I used the Instapaper `csv` template and put them in there and *BOOM* now I have all my saved history on my lan.